# ==============================================================================
# Bytebot Hawkeye API Keys (User-Managed)
# ==============================================================================
# This file contains API keys and user-specific configuration
# System configuration is auto-managed in .env.defaults by scripts
#
# ⚠️  SECURITY WARNINGS:
# - NEVER commit docker/.env to git (already in .gitignore)
# - Rotate keys every 90 days
# - Revoke immediately if exposed
# - Monitor usage on provider dashboards
# ==============================================================================

# ==============================================================================
# QUICK START (Get Running in 3 Steps)
# ==============================================================================
# 1. Copy this file:
#    cp docker/.env.example docker/.env
#
# 2. Add ONE API key below (choose your preferred provider):
#    - ANTHROPIC_API_KEY  → Best for precision, vision tasks
#    - OPENAI_API_KEY     → Best for speed and cost
#    - OPENROUTER_API_KEY → Access 100+ models with one key
#
# 3. Start the stack:
#    ./scripts/start-stack.sh
#
# 4. Access UI:
#    http://localhost:9992
# ==============================================================================

# ==============================================================================
# REQUIRED: AI Provider API Keys (Choose At Least One)
# ==============================================================================

# ------------------------------------------------------------------------------
# Anthropic (Claude) - RECOMMENDED FOR PRECISION
# ------------------------------------------------------------------------------
# Best for: Computer use, vision tasks, complex UI interactions
# Models: Claude Opus 4, Sonnet 4.5, Sonnet 3.5
# Pricing: ~$15/1M tokens (Sonnet 3.5), ~$75/1M tokens (Opus 4)
# Free tier: No (pay-as-you-go only)
# Sign up: https://console.anthropic.com/settings/keys
#
# Why Claude?
# - Superior vision capabilities for screenshot analysis
# - Best-in-class instruction following for computer control
# - Excellent at multi-step task planning
#
ANTHROPIC_API_KEY=your-anthropic-key-here

# ------------------------------------------------------------------------------
# OpenAI (GPT) - RECOMMENDED FOR SPEED & COST
# ------------------------------------------------------------------------------
# Best for: Quick tasks, cost optimization, general purpose
# Models: GPT-4o, GPT-4o-mini, o1-preview, o1-mini
# Pricing: ~$2.50/1M tokens (GPT-4o-mini), ~$5/1M tokens (GPT-4o)
# Free tier: $5 trial credit for new accounts
# Sign up: https://platform.openai.com/api-keys
#
# Why OpenAI?
# - GPT-4o-mini is cheapest option with good quality
# - Fast inference times (< 1 second for most tasks)
# - Reliable vision support for screenshots
#
OPENAI_API_KEY=your-openai-key-here

# ------------------------------------------------------------------------------
# Google Gemini - BUDGET-FRIENDLY WITH FREE TIER
# ------------------------------------------------------------------------------
# Best for: Testing, development, budget-conscious usage
# Models: Gemini 2.0 Flash, Gemini 1.5 Pro
# Pricing: FREE tier available (60 requests/minute)
# Free tier: Yes (generous limits for development)
# Sign up: https://aistudio.google.com/apikey
#
# Why Gemini?
# - Free tier is perfect for testing Bytebot
# - Good vision capabilities
# - Fast inference with Flash models
#
GEMINI_API_KEY=your-gemini-key-here

# ==============================================================================
# OPTIONAL: Multi-Provider Aggregators
# ==============================================================================

# ------------------------------------------------------------------------------
# OpenRouter - ACCESS 100+ MODELS WITH ONE KEY
# ------------------------------------------------------------------------------
# Best for: Experimenting, model comparison, cost optimization
# Models: Claude, GPT, Gemini, Llama, Qwen, DeepSeek, Mistral, etc.
# Pricing: Varies by model (some models are FREE)
# Free tier: Many free models available (llama-3.3-70b, gemini-flash, etc.)
# Sign up: https://openrouter.ai/settings/keys
#
# Why OpenRouter?
# - Can replace individual provider keys (one key for all)
# - Access to experimental/open-source models
# - Cost-effective with free model options
# - Useful for A/B testing different models
#
# Free models available on OpenRouter:
# - google/gemini-2.0-flash-exp:free
# - meta-llama/llama-3.3-70b-instruct:free
# - qwen/qwen-2.5-72b-instruct:free
#
OPENROUTER_API_KEY=your-openrouter-key-here

# ==============================================================================
# LOCAL MODELS (No API Costs - Run on Your Hardware)
# ==============================================================================
# LMStudio - Run models locally without API keys or internet connection
#
# Setup: ./scripts/setup-lmstudio.sh
# Result: Models appear in UI under "Local Models" section
# Cost: FREE (uses your GPU/CPU)
#
# Recommended models:
# - Qwen 2.5 Coder (32B) - Best for coding tasks
# - Llama 3.3 (70B) - Best general-purpose
# - DeepSeek-R1 (14B) - Best reasoning
#
# Note: LMStudio configuration is managed in .env.defaults by setup script
# You don't need to add any keys here for local models
# ==============================================================================

# ==============================================================================
# OPTIONAL: Database Configuration
# ==============================================================================
# PostgreSQL database credentials
# Only uncomment if you need custom credentials
# Defaults are secure and work out-of-the-box
#
# Security note: Change password in production deployments!
#
# POSTGRES_USER=postgres
# POSTGRES_PASSWORD=postgres
# POSTGRES_DB=bytebotdb
#
# To connect externally for debugging:
# psql postgresql://postgres:postgres@localhost:5432/bytebotdb
# ==============================================================================

# ==============================================================================
# TESTING YOUR API KEYS
# ==============================================================================
# After starting the stack (./scripts/start-stack.sh), verify your setup:
#
# 1. Check LiteLLM proxy health:
#    curl http://localhost:4000/health
#    Expected: {"status": "healthy"}
#
# 2. List available models in UI:
#    Open http://localhost:9992/tasks
#    Check model dropdown - should show models from your configured providers
#
# 3. Create test task:
#    - Prompt: "Take a screenshot and describe what you see"
#    - Should complete in 5-10 seconds
#    - Check that model responds with screenshot description
#
# Troubleshooting:
# - 401 errors → Invalid API key format or revoked key
# - 429 errors → Rate limit exceeded (wait or upgrade plan)
# - 500 errors → Check logs: docker logs bytebot-llm-proxy
# - No models show in UI → Check that .env file is in docker/ directory
# ==============================================================================

# ==============================================================================
# COST MANAGEMENT
# ==============================================================================
# Typical costs for 100 tasks (assuming 10K tokens per task = ~8K input, ~2K output):
#
# BUDGET TIER:
# - GPT-4o-mini:       $0.25  (cheapest, surprisingly good)
# - Gemini Flash:      FREE   (with limits, then ~$0.10)
# - OpenRouter free:   FREE   (various models)
#
# BALANCED TIER:
# - GPT-4o:           $2.50   (good balance of cost/quality)
# - Claude Sonnet 3.5: $1.50  (excellent for computer use)
# - Gemini 1.5 Pro:   $1.25   (good vision capabilities)
#
# PREMIUM TIER:
# - Claude Opus 4:    $15.00  (highest quality, best reasoning)
# - GPT-4 Turbo:      $10.00  (reliable, well-tested)
# - o1-preview:       $25.00  (advanced reasoning)
#
# Cost-saving tips:
# 1. Start with GPT-4o-mini or Gemini Flash free tier
# 2. Use OpenRouter to access free models (llama-3.3-70b is excellent)
# 3. Set up spending limits in provider dashboards:
#    - OpenAI: https://platform.openai.com/settings/organization/limits
#    - Anthropic: https://console.anthropic.com/settings/limits
#    - OpenRouter: https://openrouter.ai/settings/limits
# 4. Monitor usage daily during development
# 5. Consider LMStudio for unlimited local inference (FREE, uses your hardware)
# ==============================================================================

# ==============================================================================
# SECURITY BEST PRACTICES
# ==============================================================================
# API Key Safety:
# ✅ This file (.env) is gitignored - safe to add real keys
# ✅ Keys are only loaded by Docker containers (not exposed to network)
# ✅ LiteLLM proxy handles all external API calls
#
# Recommended Practices:
# 1. Use separate keys for development vs production
# 2. Rotate keys every 90 days
# 3. Set up usage alerts in provider dashboards:
#    - OpenAI: Settings → Limits → Email alerts
#    - Anthropic: Settings → Usage → Notifications
#    - OpenRouter: Settings → Notifications
# 4. Monitor for unusual activity:
#    - Sudden spike in usage
#    - Requests from unexpected locations
#    - Models you didn't configure being used
# 5. Revoke and regenerate if:
#    - Key appears in logs or error messages
#    - Suspicious activity detected
#    - Team member with access leaves
#    - Accidental commit to git (even if removed)
#
# If key is exposed:
# 1. Immediately revoke in provider dashboard
# 2. Generate new key
# 3. Update docker/.env with new key
# 4. Restart stack: ./scripts/stop-stack.sh && ./scripts/start-stack.sh
# ==============================================================================

# ==============================================================================
# PROVIDER-SPECIFIC NOTES
# ==============================================================================
#
# ANTHROPIC (Claude):
# - Best for: Computer use, agentic workflows, vision tasks
# - Rate limits: 4,000 requests/minute (Tier 1), can increase with usage
# - Context window: 200K tokens (all models)
# - Strengths: Instruction following, safety, long context
# - Dashboard: https://console.anthropic.com/
#
# OPENAI (GPT):
# - Best for: General purpose, fast inference, wide model selection
# - Rate limits: Varies by tier (500-10K requests/minute)
# - Context window: 128K (GPT-4o), 200K (o1)
# - Strengths: Speed, reliability, ecosystem
# - Dashboard: https://platform.openai.com/usage
#
# GOOGLE (Gemini):
# - Best for: Free tier testing, budget-conscious production
# - Rate limits: 60 requests/minute (free), 1000/min (paid)
# - Context window: 1M tokens (Gemini 1.5 Pro)
# - Strengths: Cost-effectiveness, massive context window
# - Dashboard: https://aistudio.google.com/
#
# OPENROUTER:
# - Best for: Multi-model experimentation, cost optimization
# - Rate limits: Depends on underlying model provider
# - Access: All major models through unified API
# - Strengths: Flexibility, free model options, load balancing
# - Dashboard: https://openrouter.ai/activity
# ==============================================================================

# ==============================================================================
# TROUBLESHOOTING COMMON ISSUES
# ==============================================================================
#
# Problem: "401 Authentication Error"
# Solution:
# - Check key format (should start with sk-, sk-ant-, etc.)
# - Verify key hasn't been revoked in provider dashboard
# - Ensure no extra spaces or quotes around key
# - Restart stack after changing .env: ./scripts/start-stack.sh
#
# Problem: "429 Rate Limit Exceeded"
# Solution:
# - Wait 60 seconds and retry
# - Check provider dashboard for current limits
# - Upgrade to higher tier if needed
# - Spread requests across multiple providers
#
# Problem: "Models not showing in UI"
# Solution:
# - Verify .env file is in docker/ directory (not project root)
# - Check docker logs: docker logs bytebot-llm-proxy
# - Restart LiteLLM proxy: docker restart bytebot-llm-proxy
# - Verify litellm-config.yaml includes your providers
#
# Problem: "High API costs"
# Solution:
# - Switch to GPT-4o-mini or Gemini Flash
# - Use OpenRouter free models
# - Set up LMStudio for local inference
# - Enable usage alerts in provider dashboards
# - Review task prompts for efficiency
#
# Problem: "Slow responses"
# Solution:
# - Use faster models (GPT-4o-mini, Gemini Flash)
# - Check network latency to provider
# - Consider local LMStudio models (instant, no network)
# - Reduce context size in prompts
#
# Problem: "Keys not loading"
# Solution:
# - Check file is named exactly: docker/.env (not .env.txt or docker.env)
# - Verify no BOM or special characters (use plain text editor)
# - Check file permissions: chmod 600 docker/.env
# - Restart entire stack: ./scripts/stop-stack.sh && ./scripts/start-stack.sh
# ==============================================================================

# ==============================================================================
# ADDITIONAL RESOURCES
# ==============================================================================
# Documentation: See README.md and docs/ directory
# Scripts Guide: scripts/README.md
# GPU Setup: docs/GPU_SETUP.md
# Windows Setup: docs/WINDOWS_SETUP.md
# macOS Setup: docs/MACOS_SETUP.md
#
# Community & Support:
# - GitHub Issues: https://github.com/your-repo/issues
# - Documentation: https://your-docs-site.com
#
# Provider Documentation:
# - Anthropic: https://docs.anthropic.com/
# - OpenAI: https://platform.openai.com/docs
# - Google AI: https://ai.google.dev/docs
# - OpenRouter: https://openrouter.ai/docs
# - LMStudio: https://lmstudio.ai/docs
# ==============================================================================
