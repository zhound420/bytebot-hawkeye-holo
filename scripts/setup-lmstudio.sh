#!/bin/bash
set -e
set -o pipefail

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
BLUE='\033[0;34m'
YELLOW='\033[1;33m'
CYAN='\033[0;36m'
NC='\033[0m' # No Color

# Get script directory and project root
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
PROJECT_ROOT="$(dirname "$SCRIPT_DIR")"

echo ""
echo -e "${BLUE}════════════════════════════════════════════════${NC}"
echo -e "${BLUE}   LMStudio Local Model Configuration${NC}"
echo -e "${BLUE}════════════════════════════════════════════════${NC}"
echo ""

# Prompt for LMStudio server address
echo -e "${CYAN}Enter LMStudio server IP:port${NC}"
echo -e "${YELLOW}(default: 192.168.4.112:1234)${NC}"
read -p "LMStudio URL: " -r LMSTUDIO_INPUT
echo ""

# Use default if empty
LMSTUDIO_URL="${LMSTUDIO_INPUT:-192.168.4.112:1234}"

# Ensure http:// prefix
if [[ ! "$LMSTUDIO_URL" =~ ^https?:// ]]; then
    LMSTUDIO_URL="http://${LMSTUDIO_URL}"
fi

echo -e "${BLUE}Testing connection to ${LMSTUDIO_URL}...${NC}"

# Test connectivity and fetch models
if ! MODELS_JSON=$(curl -sf --max-time 10 "${LMSTUDIO_URL}/v1/models" 2>/dev/null); then
    echo -e "${RED}✗ Failed to connect to LMStudio server${NC}"
    echo ""
    echo "Please ensure:"
    echo "  1. LMStudio is running on ${LMSTUDIO_URL}"
    echo "  2. The server is accessible from this machine"
    echo "  3. No firewall blocking the connection"
    echo ""
    exit 1
fi

# Parse model list
MODELS=($(echo "$MODELS_JSON" | grep -o '"id"[[:space:]]*:[[:space:]]*"[^"]*"' | sed 's/.*"\([^"]*\)".*/\1/' 2>/dev/null || echo ""))

if [ ${#MODELS[@]} -eq 0 ]; then
    echo -e "${RED}✗ No models found on LMStudio server${NC}"
    echo ""
    echo "Please load at least one model in LMStudio and try again."
    exit 1
fi

echo -e "${GREEN}✓ Connected successfully${NC}"
echo ""
echo -e "${CYAN}Found ${#MODELS[@]} model(s):${NC}"

# Display models with vision detection
declare -A MODEL_VISION
for i in "${!MODELS[@]}"; do
    MODEL_NAME="${MODELS[$i]}"

    # Detect vision models by common patterns in name
    SUPPORTS_VISION="false"
    if [[ "$MODEL_NAME" =~ (vl|vision|llava|qwen.*vl|cogvlm|internvl|kimi-vl|yi-vision) ]]; then
        SUPPORTS_VISION="true"
        echo -e "  ${GREEN}$(($i + 1)).${NC} ${MODEL_NAME} ${BLUE}[Vision]${NC}"
    else
        echo -e "  ${YELLOW}$(($i + 1)).${NC} ${MODEL_NAME} ${YELLOW}[Text-Only]${NC}"
    fi

    MODEL_VISION["$MODEL_NAME"]="$SUPPORTS_VISION"
done
echo ""

# Ask which models to enable
echo -e "${CYAN}Select models to enable (comma-separated numbers, or 'all'):${NC}"
read -p "Models: " -r MODEL_SELECTION
echo ""

# Parse selection
SELECTED_MODELS=()
if [[ "$MODEL_SELECTION" == "all" ]]; then
    SELECTED_MODELS=("${MODELS[@]}")
else
    IFS=',' read -ra INDICES <<< "$MODEL_SELECTION"
    for idx in "${INDICES[@]}"; do
        # Trim whitespace
        idx=$(echo "$idx" | xargs)
        if [[ "$idx" =~ ^[0-9]+$ ]] && [ "$idx" -ge 1 ] && [ "$idx" -le "${#MODELS[@]}" ]; then
            SELECTED_MODELS+=("${MODELS[$(($idx - 1))]}")
        fi
    done
fi

if [ ${#SELECTED_MODELS[@]} -eq 0 ]; then
    echo -e "${YELLOW}No models selected. Exiting.${NC}"
    exit 0
fi

echo -e "${GREEN}Selected ${#SELECTED_MODELS[@]} model(s):${NC}"
for model in "${SELECTED_MODELS[@]}"; do
    VISION_LABEL="Text-Only"
    if [[ "${MODEL_VISION[$model]}" == "true" ]]; then
        VISION_LABEL="${BLUE}Vision${NC}"
    fi
    echo -e "  • ${model} [${VISION_LABEL}]"
done
echo ""

echo -e "${CYAN}Note: Function calling support will be tested at runtime.${NC}"
echo -e "${CYAN}To manually test capabilities, run: ${YELLOW}./scripts/validate-lmstudio-capabilities.sh${NC}"
echo ""

# Generate LiteLLM config entries
CONFIG_FILE="${PROJECT_ROOT}/packages/bytebot-llm-proxy/litellm-config.yaml"
TEMP_CONFIG="${CONFIG_FILE}.tmp"

echo -e "${BLUE}Updating LiteLLM configuration...${NC}"

# Read existing config and find insertion point (before litellm_settings)
if [ ! -f "$CONFIG_FILE" ]; then
    echo -e "${RED}✗ Config file not found: ${CONFIG_FILE}${NC}"
    exit 1
fi

# Remove old LMStudio entries (between comment markers)
awk '
    /^# LMStudio Local Models - AUTO-GENERATED/ { skip=1; next }
    /^# END LMStudio Local Models/ { skip=0; next }
    !skip { print }
' "$CONFIG_FILE" > "$TEMP_CONFIG"

# Find insertion point (before litellm_settings or at end of model_list)
INSERTION_LINE=$(grep -n "^litellm_settings:" "$TEMP_CONFIG" | head -1 | cut -d: -f1)
if [ -z "$INSERTION_LINE" ]; then
    # No litellm_settings found, append to end
    INSERTION_LINE=$(wc -l < "$TEMP_CONFIG")
    INSERTION_LINE=$((INSERTION_LINE + 1))
fi

# Generate new LMStudio entries
{
    head -n $((INSERTION_LINE - 1)) "$TEMP_CONFIG"
    echo "# LMStudio Local Models - AUTO-GENERATED by scripts/setup-lmstudio.sh"
    echo "# To reconfigure, run: ./scripts/setup-lmstudio.sh"

    for model in "${SELECTED_MODELS[@]}"; do
        # Sanitize model name for use in model_name field (replace slashes and special chars)
        SAFE_MODEL_NAME=$(echo "$model" | sed 's/[^a-zA-Z0-9._-]/-/g')

        echo "  - model_name: local-${SAFE_MODEL_NAME}"
        echo "    litellm_params:"
        echo "      model: openai/${model}"
        echo "      api_base: os.environ/LMSTUDIO_BASE_URL"
        echo "      api_key: lm-studio"
        echo "      supports_function_calling: true"

        if [[ "${MODEL_VISION[$model]}" == "true" ]]; then
            echo "    model_info:"
            echo "      supports_vision: true"
            echo "      base_model: lmstudio"
            echo "      supports_function_calling: true"
        else
            echo "    model_info:"
            echo "      supports_vision: false"
            echo "      base_model: lmstudio"
            echo "      supports_function_calling: true"
        fi
    done

    echo "# END LMStudio Local Models"
    echo ""
    tail -n +$INSERTION_LINE "$TEMP_CONFIG"
} > "${CONFIG_FILE}.new"

mv "${CONFIG_FILE}.new" "$CONFIG_FILE"
rm "$TEMP_CONFIG"

echo -e "${GREEN}✓ LiteLLM config updated${NC}"
echo ""

# Update docker/.env.defaults file (system config - Docker Compose loads both .env.defaults and .env)
ENV_FILE="${PROJECT_ROOT}/docker/.env.defaults"

if [ ! -f "$ENV_FILE" ]; then
    echo -e "${RED}✗ docker/.env.defaults not found${NC}"
    exit 1
fi

echo -e "${BLUE}Updating docker/.env.defaults (system configuration)...${NC}"

# Update or add LMSTUDIO variables
if grep -q "^LMSTUDIO_ENABLED=" "$ENV_FILE"; then
    sed -i.bak 's|^LMSTUDIO_ENABLED=.*|LMSTUDIO_ENABLED=true|' "$ENV_FILE"
else
    echo "LMSTUDIO_ENABLED=true" >> "$ENV_FILE"
fi

if grep -q "^LMSTUDIO_BASE_URL=" "$ENV_FILE"; then
    sed -i.bak "s|^LMSTUDIO_BASE_URL=.*|LMSTUDIO_BASE_URL=${LMSTUDIO_URL}/v1|" "$ENV_FILE"
else
    echo "LMSTUDIO_BASE_URL=${LMSTUDIO_URL}/v1" >> "$ENV_FILE"
fi

# Clean up backup files
rm -f "${ENV_FILE}.bak"

echo -e "${GREEN}✓ Environment variables updated${NC}"
echo ""

# Summary
echo -e "${GREEN}════════════════════════════════════════════════${NC}"
echo -e "${GREEN}   LMStudio Configuration Complete!${NC}"
echo -e "${GREEN}════════════════════════════════════════════════${NC}"
echo ""
echo -e "${CYAN}Summary:${NC}"
echo "  • Server: ${LMSTUDIO_URL}"
echo "  • Models enabled: ${#SELECTED_MODELS[@]}"
echo "  • Config: packages/bytebot-llm-proxy/litellm-config.yaml"
echo "  • System config: docker/.env.defaults"
echo ""
echo -e "${YELLOW}Next steps:${NC}"
echo "  1. Restart the stack to load new models:"
echo -e "     ${CYAN}./scripts/stop-stack.sh && ./scripts/start-stack.sh${NC}"
echo "  2. Models will appear in the UI model picker under 'Local Models'"
echo "  3. To reconfigure: ${CYAN}./scripts/setup-lmstudio.sh${NC}"
echo ""
echo -e "${CYAN}Optional:${NC}"
echo "  • To manually test function calling capabilities:"
echo -e "    ${CYAN}./scripts/validate-lmstudio-capabilities.sh${NC}"
echo ""
